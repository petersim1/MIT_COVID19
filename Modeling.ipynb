{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique_ID                               object\n",
       "date                                    object\n",
       "county                                  object\n",
       "state                                   object\n",
       "fips                                   float64\n",
       "cases                                    int64\n",
       "deaths                                   int64\n",
       "Latitude                               float64\n",
       "Longitude                              float64\n",
       "Total_Hospital_Beds                     object\n",
       "Total_ICU_Beds                          object\n",
       "Available_Hospital_Beds                 object\n",
       "Potentially_Available_Hospital_Beds     object\n",
       "Available_ICU_Beds                     float64\n",
       "Potentially_Available_ICU_Beds          object\n",
       "Adult_Population                        object\n",
       "Population_65+                          object\n",
       "Area_(sqmi)                            float64\n",
       "Population                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv('data_cleaned/MERGED_PETER.csv')\n",
    "\n",
    "DF = DF[~pd.isna(DF['Population'])]\n",
    "DF = DF[~pd.isna(DF['Area_(sqmi)'])].reset_index(drop=True)\n",
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique_ID                               object\n",
       "date                                    object\n",
       "county                                  object\n",
       "state                                   object\n",
       "fips                                   float64\n",
       "cases                                  float64\n",
       "deaths                                 float64\n",
       "Latitude                               float64\n",
       "Longitude                              float64\n",
       "Total_Hospital_Beds                    float64\n",
       "Total_ICU_Beds                         float64\n",
       "Available_Hospital_Beds                float64\n",
       "Potentially_Available_Hospital_Beds    float64\n",
       "Available_ICU_Beds                     float64\n",
       "Potentially_Available_ICU_Beds         float64\n",
       "Adult_Population                       float64\n",
       "Population_65+                         float64\n",
       "Area_(sqmi)                            float64\n",
       "Population                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in DF.columns[5:] :\n",
    "    DF[col] = DF[col].apply(lambda x : float(str(x).replace(',','')))\n",
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_ids = np.unique(DF.loc[~pd.isna(DF['Total_Hospital_Beds']),['Unique_ID']].values)\n",
    "\n",
    "item_seen = []\n",
    "hospital_locations = []\n",
    "for i,v in DF.iterrows() :\n",
    "    if v['Unique_ID'] in hospital_ids :\n",
    "        if v['Unique_ID'] not in item_seen :\n",
    "            item_seen.append(v['Unique_ID'])\n",
    "            hospital_locations.append([v['Latitude'],v['Longitude']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Pop_Density'] = DF['Population']/DF['Area_(sqmi)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_city_ids = set(DF[DF['Pop_Density'] >= 3000]['Unique_ID'])\n",
    "\n",
    "item_seen = []\n",
    "big_city_locations = []\n",
    "for i,v in DF.iterrows() :\n",
    "    if v['Unique_ID'] in big_city_ids :\n",
    "        if v['Unique_ID'] not in item_seen :\n",
    "            item_seen.append(v['Unique_ID'])\n",
    "            big_city_locations.append([v['Latitude'],v['Longitude']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Proximity(location_x,location_y,city_loc,hospital_loc) :\n",
    "    \n",
    "    min_distance_city = 1e10\n",
    "    for loc in city_loc :\n",
    "        dis = np.sqrt((loc[0] - location_x)**2 + (loc[1] - location_y)**2)\n",
    "        if dis < min_distance_city :\n",
    "            min_distance_city = dis\n",
    "            \n",
    "    min_distance_hosp = 1e10\n",
    "    for loc in hospital_loc :\n",
    "        dis = np.sqrt((loc[0] - location_x)**2 + (loc[1] - location_y)**2)\n",
    "        if dis < min_distance_hosp :\n",
    "            min_distance_hosp = dis\n",
    "            \n",
    "    return min_distance_city,min_distance_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,500,1000,1500,2000,2500,3000,3500,4000,4500,5000,5500,6000,6500,7000,7500,8000,8500,9000,9500,10000,10500,11000,11500,12000,12500,13000,13500,14000,14500,15000,15500,16000,16500,17000,17500,18000,18500,19000,19500,20000,20500,21000,21500,22000,22500,23000,23500,24000,24500,25000,25500,26000,26500,"
     ]
    }
   ],
   "source": [
    "nearest_big_city,nearest_hospital = [],[]\n",
    "for i,v in DF.iterrows() :\n",
    "    if i%500 == 0 :print(i,end=',')\n",
    "    cit,hos = Proximity(v['Latitude'],v['Longitude'],big_city_locations,hospital_locations)\n",
    "    nearest_big_city.append(cit)\n",
    "    nearest_hospital.append(hos)\n",
    "\n",
    "DF['Nearest_Hospital'] = nearest_hospital\n",
    "DF['Nearest_BigCity'] = nearest_big_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = {uid:sorted(DF[DF['Unique_ID'] == uid]['date'])[0] for uid in DF['Unique_ID'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_before = []\n",
    "for date in DF['date'] :\n",
    "    minus_one = datetime.datetime.strptime(date,'%Y-%M-%d') - datetime.timedelta(days=1)\n",
    "    day_before.append(datetime.datetime.strftime(minus_one,'%Y-%M-%d'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['day_before_index'] = day_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_Cases(col) :\n",
    "    \n",
    "    new_cases_per_day = []\n",
    "    \n",
    "    for i,v in DF.iterrows() :\n",
    "        \n",
    "        unique_id = v['Unique_ID']\n",
    "        date = v['date']\n",
    "        if date == min_date[unique_id] :\n",
    "            to_add = v[col]\n",
    "        else :\n",
    "            try :\n",
    "                to_subtract = DF[(DF['Unique_ID'] == unique_id) & (DF['date'] == v['day_before_index'])][col].values[0]\n",
    "                to_add = v[col] - to_subtract\n",
    "            except :\n",
    "                to_add = np.nan\n",
    "        new_cases_per_day.append(to_add)    \n",
    "    return new_cases_per_day\n",
    "        \n",
    "        \n",
    "    \n",
    "DF['New_Cases'] = New_Cases('cases') \n",
    "DF['New_Deaths'] = New_Cases('deaths') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('data_cleaned/Distance_Calculations.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in Steve's lagged dataframe\n",
    "\n",
    "DF = pd.read_csv('output/MASTER_filtered_withlag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Total_Hospital_Beds</th>\n",
       "      <th>...</th>\n",
       "      <th>Area_.sqmi.</th>\n",
       "      <th>Population</th>\n",
       "      <th>Pop_Density</th>\n",
       "      <th>Nearest_Hospital</th>\n",
       "      <th>Nearest_BigCity</th>\n",
       "      <th>day_before_index</th>\n",
       "      <th>New_Cases</th>\n",
       "      <th>New_Deaths</th>\n",
       "      <th>day_before_cases</th>\n",
       "      <th>day_before_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snohomish_Washington</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.046160</td>\n",
       "      <td>-121.717070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>822083</td>\n",
       "      <td>393.341148</td>\n",
       "      <td>1.866215</td>\n",
       "      <td>10.319262</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snohomish_Washington</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.046160</td>\n",
       "      <td>-121.717070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>822083</td>\n",
       "      <td>393.341148</td>\n",
       "      <td>1.866215</td>\n",
       "      <td>10.319262</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snohomish_Washington</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.046160</td>\n",
       "      <td>-121.717070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>822083</td>\n",
       "      <td>393.341148</td>\n",
       "      <td>1.866215</td>\n",
       "      <td>10.319262</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cook_Illinois</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Cook</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17031.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41.841448</td>\n",
       "      <td>-87.816588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>946.0</td>\n",
       "      <td>5150233</td>\n",
       "      <td>5444.220930</td>\n",
       "      <td>1.173137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snohomish_Washington</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53061.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.046160</td>\n",
       "      <td>-121.717070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>822083</td>\n",
       "      <td>393.341148</td>\n",
       "      <td>1.866215</td>\n",
       "      <td>10.319262</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unique_ID        date     county       state     fips  cases  \\\n",
       "0  Snohomish_Washington  2020-01-21  Snohomish  Washington  53061.0      1   \n",
       "1  Snohomish_Washington  2020-01-22  Snohomish  Washington  53061.0      1   \n",
       "2  Snohomish_Washington  2020-01-23  Snohomish  Washington  53061.0      1   \n",
       "3         Cook_Illinois  2020-01-24       Cook    Illinois  17031.0      1   \n",
       "4  Snohomish_Washington  2020-01-24  Snohomish  Washington  53061.0      1   \n",
       "\n",
       "   deaths   Latitude   Longitude  Total_Hospital_Beds  ...  Area_.sqmi.  \\\n",
       "0       0  48.046160 -121.717070                  NaN  ...       2090.0   \n",
       "1       0  48.046160 -121.717070                  NaN  ...       2090.0   \n",
       "2       0  48.046160 -121.717070                  NaN  ...       2090.0   \n",
       "3       0  41.841448  -87.816588                  NaN  ...        946.0   \n",
       "4       0  48.046160 -121.717070                  NaN  ...       2090.0   \n",
       "\n",
       "   Population  Pop_Density  Nearest_Hospital  Nearest_BigCity  \\\n",
       "0      822083   393.341148          1.866215        10.319262   \n",
       "1      822083   393.341148          1.866215        10.319262   \n",
       "2      822083   393.341148          1.866215        10.319262   \n",
       "3     5150233  5444.220930          1.173137         0.000000   \n",
       "4      822083   393.341148          1.866215        10.319262   \n",
       "\n",
       "   day_before_index  New_Cases  New_Deaths  day_before_cases  \\\n",
       "0        2020-01-20        1.0         0.0               NaN   \n",
       "1        2020-01-21        0.0         0.0               1.0   \n",
       "2        2020-01-22        0.0         0.0               0.0   \n",
       "3        2020-01-23        1.0         0.0               NaN   \n",
       "4        2020-01-23        0.0         0.0               0.0   \n",
       "\n",
       "   day_before_deaths  \n",
       "0                NaN  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                NaN  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['cases_normalized'] = DF['New_Cases']/DF['Population']\n",
    "DF['day_before_cases_normalized'] = DF['day_before_cases']/DF['Population']\n",
    "\n",
    "DF['day_before_deaths_normalized'] = DF['day_before_deaths']/DF['Population']\n",
    "\n",
    "DF = DF[~pd.isna(DF['day_before_cases_normalized'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_holdout = []\n",
    "\n",
    "unique_ids = DF['Unique_ID'].unique()\n",
    "holdouts = {}\n",
    "\n",
    "for county in unique_ids :\n",
    "    \n",
    "    subbed = DF[DF['Unique_ID'] == county]\n",
    "    to_hold = sorted(subbed['date'])[-2:]\n",
    "    holdouts[county] = to_hold\n",
    "\n",
    "holdout_indices = []\n",
    "for i,v in DF.iterrows() :\n",
    "    \n",
    "    unique_id = v['Unique_ID']\n",
    "    if v['date'] in holdouts[unique_id] :\n",
    "        holdout_indices.append(i)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Holdout_Set = DF.iloc[holdout_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = np.setdiff1d(list(DF.index),holdout_indices)\n",
    "\n",
    "Training_Set = DF.iloc[indices_train].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['date','county','state','fips','Latitude','Longitude','Total_Hospital_Beds', 'Total_ICU_Beds',\n",
    "       'Available_Hospital_Beds', 'Potentially_Available_Hospital_Beds',\n",
    "       'Available_ICU_Beds', 'Potentially_Available_ICU_Beds',\n",
    "       'Adult_Population', 'Population_65.','Area_.sqmi.','day_before_index','cases','deaths',\n",
    "            'day_before_cases', 'day_before_deaths','cases','cases_normalized']\n",
    "\n",
    "Holdout_Set_X,Holdout_Set_Y = Holdout_Set.drop(cols_drop,axis=1),Holdout_Set['cases_normalized']\n",
    "Training_Set_X,Training_Set_Y = Training_Set.drop(cols_drop,axis=1),Training_Set['cases_normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Holdout_Set_X.to_csv('output/Holdout_Set_X.csv',index=True)\n",
    "Holdout_Set_Y.to_csv('output/Holdout_Set_Y.csv',index=True)\n",
    "Training_Set_X.to_csv('output/Training_Set_X.csv',index=True)\n",
    "Training_Set_Y.to_csv('output/Training_Set_Y.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now actually Model the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize_Data(Train_X,Test_X) :\n",
    "    \n",
    "    mean_vals = {}\n",
    "    std_vals = {}\n",
    "    \n",
    "    for col in Train_X.columns :\n",
    "        mean_vals[col] = np.mean(Train_X[col])\n",
    "        std_vals[col] = np.std(Train_X[col])\n",
    "        \n",
    "        Train_X[col] = (Train_X[col] - mean_vals[col])/std_vals[col]\n",
    "        Test_X[col] = (Test_X[col] - mean_vals[col])/std_vals[col]\n",
    "        \n",
    "    return Train_X,Test_X,mean_vals,std_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_inds = np.random.permutation(Training_Set_X.index)\n",
    "\n",
    "percent_training=.7\n",
    "\n",
    "trainings_ind = rand_inds[:int(percent_training*len(rand_inds))]\n",
    "testing_ind = rand_inds[int(percent_training*len(rand_inds)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
